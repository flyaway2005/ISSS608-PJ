[
  {
    "objectID": "Proposal/proposal.html",
    "href": "Proposal/proposal.html",
    "title": "Project Proposal",
    "section": "",
    "text": "Government procurement represents billions in public spending annually, directly impacting taxpayers and the business ecosystem. Despite initiatives like GeBIZ that ostensibly promote transparency, meaningful public oversight remains challenging. Our team’s experience attempting to analyze this data revealed significant barriers to understanding: scattered information across thousands of entries, complex relationships between agencies and suppliers, and limited tools to identify patterns or anomalies in spending.\n\n\n\nWhile raw procurement data is technically “available,” several critical issues prevent it from being truly accessible:\n\nInformation Overload: The volume and complexity of government tender data overwhelm ordinary citizens.\nLimited Visualization: Current platforms present data in tabular formats without meaningful visual representations of relationships or trends.\nHidden Patterns: Important insights about procurement patterns, supplier dominance, and potential inefficiencies remain buried in spreadsheets.\nAccessibility Barriers: Technical knowledge requirements effectively restrict who can meaningfully engage with and interpret public spending information.\n\n\n\n\nTo bridge this gap, our project “Let’s Track Public Dollars! Unveiling the G2B Network from GeBiz” aims to address these challenges by developing an intuitive Shiny dashboard that transforms complex procurement data into accessible and insightful visualizations.\nThe application will leverage:\n\nMachine Learning-Based Tender Categorization: Uses text analysis to classify tenders via its description, enabling grouped analysis by supervised category to reveal agency procurement trends and supplier market dominance.\nProcurement Dashboard: Visualises procurement trends over time, revealing seasonal patterns, supplier shifts, and spending changes by tender type. It also analyzes market concentration and supplier dominance.\nNetwork Analysis: Visualises agency-supplier relationships and identifies key players in procurement clusters. Features multiple filters by tender category, agencies, suppliers, and date ranges with highlights of top suppliers and agencies.\n\nThrough these visual analytics approaches, users will understand immediately: \n\nHow government spending flows & distribution between agencies and suppliers \nWhich suppliers dominate particular agency relationships \nHow procurement patterns evolve over fiscal periods \nWhere potential opportunities exist for new market entrants \nWhether procurement appears appropriately distributed or concentrated \n\nOur solutions will empower citizens, businesses, and policymakers with the tool to understand government spending, and contracts without specialised technical knowledge. Ultimately we want to promote greater accountability by shedding light on procurement patterns, key suppliers, and competitive landscapes, as well as informed public resource allocation.\n\n\n\nGeBIZ (Government Electronic Business Platform), containing 18,638 entries from 2019 to 2023.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntender_no\ntender_description\nagency\naward_date\ntender_detail_status\nsupplier_name\nawarded_amt\n\n\n\n\nACR000ETT18300010\nSUPPLY, DESIGN, DEVELOPMENT, CUSTOMIZATION, DELIVERY, INSTALLATION, TESTING, COMMISSIONING AND MAINTENANCE OF A VARIABLE CAPITAL COMPANIES (VCC) SYSTEM FOR ACCOUNTING AND CORPORATE REGULARTORY AUTHORITY\nAccounting And Corporate Regulatory Authority\n11/6/2019\nAwarded to Suppliers\nAZAAS PTE. LTD.\n2305880\n\n\nACR000ETT18300011\nAPPLICATION ENHANCEMENT, CUSTOMISATION, MIGRATION, DELIVERY, INSTALLATION, TESTING AND COMMISSIONING OF THE FULLY OPERATIONAL BIZFINx 2.0 APPLICATION SYSTEM WITH AN OPTION FOR MAINTENANCE\nAccounting And Corporate Regulatory Authority\n10/5/2019\nAwarded to No Suppliers\nUnknown\n0\n\n\nACR000ETT19300001\nPROVISION OF CONSULTANCY SERVICES FOR STRATEGIC BUSINESS PROCESSES RE-ENGINEERING (SBPR) AND ACRA’S IT INFRASTRUCTURE\nAccounting And Corporate Regulatory Authority\n30/4/2019\nAwarded to Suppliers\nACCENTURE SG SERVICES PTE. LTD.\n2035000\n\n\nACR000ETT19300002\nSUPPLY, DELIVERY, DESIGN, CUSTOMISATION, INSTALLATION, CONFIGURATION, TESTING, COMMISSIONING OF A FULLY OPERATIONAL BIZFILE+ WITH AN OPTION FOR MAINTENANCE\nAccounting And Corporate Regulatory Authority\n29/8/2019\nAwarded to Suppliers\nTECH MAHINDRA LIMITED (SINGAPORE BRANCH)\n30700374\n\n\nACR000ETT19300003\nPROVISION OF MEDIA MONITORING SERVICES FOR A PERIOD OF TWO YEARS WITH OPTION TO EXTEND FOR UP TO ONE YEAR\nAccounting And Corporate Regulatory Authority\n6/8/2019\nAwarded to Suppliers\nINSIGHTMATRIX\n178800\n\n\nACR000ETT19300004\nINVITATION TO TENDER FOR THE PROVISION OF CALL CENTRE SERVICES FOR ACCOUNTING AND CORPORATE REGULATORY AUTHORITY FOR A PERIOD OF 3 YEARS WITH OPTION OF UP TO 2 EXTENSIONS OF 2 YEARS EACH\nAccounting And Corporate Regulatory Authority\n5/11/2019\nAwarded to Suppliers\nTDCX (SG) PTE. LTD.\n8566831\n\n\n\n\n\n\n\n\nThe project will employ a modular data-driven approach to uncover insights from government procurement data using interactive dashboards, topic modeling, and network analysis techniques. By integrating advanced visualization and machine learning methods, the system will provide a comprehensive, transparent, and engaging analytical tool for public procurement monitoring. The planning modules include the following: \n\n\n\n\n\n\n\nThis module adopts a complete Latent Dirichlet Allocation (LDA) text modeling approach to automatically categorize government tenders based on procurement descriptions. It comprises two key submodules:\n\nLDA Supervised Classification, which uses predefined procurement categories to train the model and label tenders accordingly\nLDA Clustering (Unsupervised), which allows users to explore underlying topic structures without category supervision.\n\nUsers can control the sample size (e.g., 1,000, 5,000, 10,000, or all) from a pre-cleaned dataset (Cleaned_GP_LDA.csv) and then conduct analysis accordingly. This flexibility allows scalable experimentation and ensures robust and interpretable insights from both supervised and unsupervised LDA.\n\n\n\n\n\n\n\nUsers begin by selecting a sample size from the full cleaned tender dataset.\nThe app draws random samples from Cleaned_GP_LDA.csv, which has undergone preprocessing (punctuation removal, case normalization, stopword removal).\nThis step ensures consistency and readiness for text modeling.\n\n\n\n\nObjective: Train an LDA model using 7 predefined procurement categories, then assign one category to each tender.\nWorkflow:\n\nAn LDA model is trained with a fixed number of topics (k = 7) using pre-annotated labels.\nEach tender is assigned to a category based on the most probable topic.\nThe labeled dataset is exported (tender_lda_labeled_all.csv) for downstream analysis.\n\nUser Controls & Visualizations:\n\nWord count selector: Choose the number of top words to display per category.\nLDA Category Filter: Focus on one or all categories.\nLDA Distribution Chart: View the number of tenders per category\nTF-IDF Table: Examine top words by TF-IDF per category.\nWordcloud: Visualize dominant words per category.\nTF-IDF Bar Chart: Explore the top terms and their TF-IDF scores in a bar plot.\n\nKey Benefits:\n\nEnables consistent labeling of tenders using domain-specific procurement logic.\nProvides clear visual patterns for each procurement category.\n\n\n\n\nObjective: Explore latent structures in tender descriptions without using predefined labels.\nWorkflow:\n\nThe user specifies the number of clusters k and a fixed topic number (k = 10) for the LDA model.\nAfter modeling, a k-means algorithm is applied to cluster the tender-topic matrix.\nEach cluster reveals a pattern of topic distribution and representative keywords.\n\nVisual Outputs:\n\nAll Cluster View: Visualize how tenders are grouped by topic across different clusters.\nSingle Cluster View: Drill into a specific cluster to analyze its topic weight and top words.\nTF-IDF Insights: For each topic, the top 5 words with the highest beta values are displayed.\n\nKey Benefits:\n\nFacilitates discovery of procurement themes not captured by predefined categories.\nHighlights hidden textual patterns in tenders using a data-driven approach.\n\n\n\n\n\n\nText Pattern Discovery: Identify linguistic and thematic patterns in tender descriptions using both guided and unguided modeling.\nFlexible Exploration: Support user-defined sampling, keyword visualization, and model configuration.\nSupports Strategic Analysis: Enables users to better understand procurement trends, supplier profiles, and category distributions.\n\n\n\n\n\n\nThe Procurement Dashboard is an interactive module providing real-time insights into procurement activities, supplier competition, and market dynamics. By leveraging advanced visualization, filtering, and anomaly detection, it offers a comprehensive and transparent view of procurement trends.\n\n\n\n\nTime-Based Analysis Interactive time series charts with customisable periods, complemented by calendar heat maps that highlight seasonal patterns and procurement cycles.\nComponent Owner: Cathy CHU Shan-hui\nAgency Explorer Dynamic visualisation of top agencies with comparison tools, featuring distribution views and timeline charts to track spending patterns across different government entities.\nComponent Owner: Cathy CHU Shan-hui\nSupplier Analysis Comprehensive supplier metrics dashboard showing concentration statistics and temporal activity patterns to identify key vendors and their engagement over time.\nComponent Owner: Cathy CHU Shan-hui\nTender Analysis Tools for analysing tender value distribution by type, with capabilities to identify outliers and track frequency trends across the procurement landscape.\nComponent Owner: Chang Fang Yu\nInteractive Controls Unified control panel with filters for date ranges, agencies, suppliers, tender types and award amounts.\n\n\n\n\n\nReal-time Procurement Trends : Visualisation of temporal spending patterns including month-over-month changes, year-over-year comparisons, and identification of peak procurement periods tied to budget cycles.\nAgency-Level Procurement Analysis : Identification of top spending agencies with their specialization patterns. Enable comparative analysis to spot unusual procurement behaviors and spending anomalies.\nSupplier Market Presence : Track key suppliers, awarded contracts, and market concentration.\nMarket Share & Competitive : Evaluate supplier dominance, competition, and procurement fairness across agencies.\n\n\n\n\n\n\n\n\n\n\nA network graph visualization will be developed to illustrate the relationships between government agencies and suppliers based on procurement transactions.  \n\n\n\n\nInteractive network visualisation (core) \nFiltering and control panel (core) \nNetwork metrics dashboard (core) \nCommunity detection \nEntity focus view \n\n\n\n\n\nAgency-supplier collaboration: which agencies work most frequently with specific suppliers \nNetwork centrality analysis: Identify central nodes in procurement networks \nCommunity detection: will reveal clusters of agencies and suppliers that frequently collaborate. \n\n\n\n\n\n\n\nTender ClassificationProcurement DashboardNetwork Analysis\n\n\nTo update\n\n\n\n\n\n\n\nNetwork visualisation \nCommunity detection \nNetwork metrics"
  },
  {
    "objectID": "Proposal/proposal.html#motivation",
    "href": "Proposal/proposal.html#motivation",
    "title": "Project Proposal",
    "section": "",
    "text": "Government procurement represents billions in public spending annually, directly impacting taxpayers and the business ecosystem. Despite initiatives like GeBIZ that ostensibly promote transparency, meaningful public oversight remains challenging. Our team’s experience attempting to analyze this data revealed significant barriers to understanding: scattered information across thousands of entries, complex relationships between agencies and suppliers, and limited tools to identify patterns or anomalies in spending."
  },
  {
    "objectID": "Proposal/proposal.html#problem-statement",
    "href": "Proposal/proposal.html#problem-statement",
    "title": "Project Proposal",
    "section": "",
    "text": "While raw procurement data is technically “available,” several critical issues prevent it from being truly accessible:\n\nInformation Overload: The volume and complexity of government tender data overwhelm ordinary citizens.\nLimited Visualization: Current platforms present data in tabular formats without meaningful visual representations of relationships or trends.\nHidden Patterns: Important insights about procurement patterns, supplier dominance, and potential inefficiencies remain buried in spreadsheets.\nAccessibility Barriers: Technical knowledge requirements effectively restrict who can meaningfully engage with and interpret public spending information."
  },
  {
    "objectID": "Proposal/proposal.html#proposed-solution",
    "href": "Proposal/proposal.html#proposed-solution",
    "title": "Project Proposal",
    "section": "",
    "text": "To bridge this gap, our project “Let’s Track Public Dollars! Unveiling the G2B Network from GeBiz” aims to address these challenges by developing an intuitive Shiny dashboard that transforms complex procurement data into accessible and insightful visualizations.\nThe application will leverage:\n\nMachine Learning-Based Tender Categorization: Uses text analysis to classify tenders via its description, enabling grouped analysis by supervised category to reveal agency procurement trends and supplier market dominance.\nProcurement Dashboard: Visualises procurement trends over time, revealing seasonal patterns, supplier shifts, and spending changes by tender type. It also analyzes market concentration and supplier dominance.\nNetwork Analysis: Visualises agency-supplier relationships and identifies key players in procurement clusters. Features multiple filters by tender category, agencies, suppliers, and date ranges with highlights of top suppliers and agencies.\n\nThrough these visual analytics approaches, users will understand immediately: \n\nHow government spending flows & distribution between agencies and suppliers \nWhich suppliers dominate particular agency relationships \nHow procurement patterns evolve over fiscal periods \nWhere potential opportunities exist for new market entrants \nWhether procurement appears appropriately distributed or concentrated \n\nOur solutions will empower citizens, businesses, and policymakers with the tool to understand government spending, and contracts without specialised technical knowledge. Ultimately we want to promote greater accountability by shedding light on procurement patterns, key suppliers, and competitive landscapes, as well as informed public resource allocation."
  },
  {
    "objectID": "Proposal/proposal.html#data",
    "href": "Proposal/proposal.html#data",
    "title": "Project Proposal",
    "section": "",
    "text": "GeBIZ (Government Electronic Business Platform), containing 18,638 entries from 2019 to 2023.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntender_no\ntender_description\nagency\naward_date\ntender_detail_status\nsupplier_name\nawarded_amt\n\n\n\n\nACR000ETT18300010\nSUPPLY, DESIGN, DEVELOPMENT, CUSTOMIZATION, DELIVERY, INSTALLATION, TESTING, COMMISSIONING AND MAINTENANCE OF A VARIABLE CAPITAL COMPANIES (VCC) SYSTEM FOR ACCOUNTING AND CORPORATE REGULARTORY AUTHORITY\nAccounting And Corporate Regulatory Authority\n11/6/2019\nAwarded to Suppliers\nAZAAS PTE. LTD.\n2305880\n\n\nACR000ETT18300011\nAPPLICATION ENHANCEMENT, CUSTOMISATION, MIGRATION, DELIVERY, INSTALLATION, TESTING AND COMMISSIONING OF THE FULLY OPERATIONAL BIZFINx 2.0 APPLICATION SYSTEM WITH AN OPTION FOR MAINTENANCE\nAccounting And Corporate Regulatory Authority\n10/5/2019\nAwarded to No Suppliers\nUnknown\n0\n\n\nACR000ETT19300001\nPROVISION OF CONSULTANCY SERVICES FOR STRATEGIC BUSINESS PROCESSES RE-ENGINEERING (SBPR) AND ACRA’S IT INFRASTRUCTURE\nAccounting And Corporate Regulatory Authority\n30/4/2019\nAwarded to Suppliers\nACCENTURE SG SERVICES PTE. LTD.\n2035000\n\n\nACR000ETT19300002\nSUPPLY, DELIVERY, DESIGN, CUSTOMISATION, INSTALLATION, CONFIGURATION, TESTING, COMMISSIONING OF A FULLY OPERATIONAL BIZFILE+ WITH AN OPTION FOR MAINTENANCE\nAccounting And Corporate Regulatory Authority\n29/8/2019\nAwarded to Suppliers\nTECH MAHINDRA LIMITED (SINGAPORE BRANCH)\n30700374\n\n\nACR000ETT19300003\nPROVISION OF MEDIA MONITORING SERVICES FOR A PERIOD OF TWO YEARS WITH OPTION TO EXTEND FOR UP TO ONE YEAR\nAccounting And Corporate Regulatory Authority\n6/8/2019\nAwarded to Suppliers\nINSIGHTMATRIX\n178800\n\n\nACR000ETT19300004\nINVITATION TO TENDER FOR THE PROVISION OF CALL CENTRE SERVICES FOR ACCOUNTING AND CORPORATE REGULATORY AUTHORITY FOR A PERIOD OF 3 YEARS WITH OPTION OF UP TO 2 EXTENSIONS OF 2 YEARS EACH\nAccounting And Corporate Regulatory Authority\n5/11/2019\nAwarded to Suppliers\nTDCX (SG) PTE. LTD.\n8566831"
  },
  {
    "objectID": "Proposal/proposal.html#methodology",
    "href": "Proposal/proposal.html#methodology",
    "title": "Project Proposal",
    "section": "",
    "text": "The project will employ a modular data-driven approach to uncover insights from government procurement data using interactive dashboards, topic modeling, and network analysis techniques. By integrating advanced visualization and machine learning methods, the system will provide a comprehensive, transparent, and engaging analytical tool for public procurement monitoring. The planning modules include the following: \n\n\n\n\n\n\n\nThis module adopts a complete Latent Dirichlet Allocation (LDA) text modeling approach to automatically categorize government tenders based on procurement descriptions. It comprises two key submodules:\n\nLDA Supervised Classification, which uses predefined procurement categories to train the model and label tenders accordingly\nLDA Clustering (Unsupervised), which allows users to explore underlying topic structures without category supervision.\n\nUsers can control the sample size (e.g., 1,000, 5,000, 10,000, or all) from a pre-cleaned dataset (Cleaned_GP_LDA.csv) and then conduct analysis accordingly. This flexibility allows scalable experimentation and ensures robust and interpretable insights from both supervised and unsupervised LDA.\n\n\n\n\n\n\n\nUsers begin by selecting a sample size from the full cleaned tender dataset.\nThe app draws random samples from Cleaned_GP_LDA.csv, which has undergone preprocessing (punctuation removal, case normalization, stopword removal).\nThis step ensures consistency and readiness for text modeling.\n\n\n\n\nObjective: Train an LDA model using 7 predefined procurement categories, then assign one category to each tender.\nWorkflow:\n\nAn LDA model is trained with a fixed number of topics (k = 7) using pre-annotated labels.\nEach tender is assigned to a category based on the most probable topic.\nThe labeled dataset is exported (tender_lda_labeled_all.csv) for downstream analysis.\n\nUser Controls & Visualizations:\n\nWord count selector: Choose the number of top words to display per category.\nLDA Category Filter: Focus on one or all categories.\nLDA Distribution Chart: View the number of tenders per category\nTF-IDF Table: Examine top words by TF-IDF per category.\nWordcloud: Visualize dominant words per category.\nTF-IDF Bar Chart: Explore the top terms and their TF-IDF scores in a bar plot.\n\nKey Benefits:\n\nEnables consistent labeling of tenders using domain-specific procurement logic.\nProvides clear visual patterns for each procurement category.\n\n\n\n\nObjective: Explore latent structures in tender descriptions without using predefined labels.\nWorkflow:\n\nThe user specifies the number of clusters k and a fixed topic number (k = 10) for the LDA model.\nAfter modeling, a k-means algorithm is applied to cluster the tender-topic matrix.\nEach cluster reveals a pattern of topic distribution and representative keywords.\n\nVisual Outputs:\n\nAll Cluster View: Visualize how tenders are grouped by topic across different clusters.\nSingle Cluster View: Drill into a specific cluster to analyze its topic weight and top words.\nTF-IDF Insights: For each topic, the top 5 words with the highest beta values are displayed.\n\nKey Benefits:\n\nFacilitates discovery of procurement themes not captured by predefined categories.\nHighlights hidden textual patterns in tenders using a data-driven approach.\n\n\n\n\n\n\nText Pattern Discovery: Identify linguistic and thematic patterns in tender descriptions using both guided and unguided modeling.\nFlexible Exploration: Support user-defined sampling, keyword visualization, and model configuration.\nSupports Strategic Analysis: Enables users to better understand procurement trends, supplier profiles, and category distributions.\n\n\n\n\n\n\nThe Procurement Dashboard is an interactive module providing real-time insights into procurement activities, supplier competition, and market dynamics. By leveraging advanced visualization, filtering, and anomaly detection, it offers a comprehensive and transparent view of procurement trends.\n\n\n\n\nTime-Based Analysis Interactive time series charts with customisable periods, complemented by calendar heat maps that highlight seasonal patterns and procurement cycles.\nComponent Owner: Cathy CHU Shan-hui\nAgency Explorer Dynamic visualisation of top agencies with comparison tools, featuring distribution views and timeline charts to track spending patterns across different government entities.\nComponent Owner: Cathy CHU Shan-hui\nSupplier Analysis Comprehensive supplier metrics dashboard showing concentration statistics and temporal activity patterns to identify key vendors and their engagement over time.\nComponent Owner: Cathy CHU Shan-hui\nTender Analysis Tools for analysing tender value distribution by type, with capabilities to identify outliers and track frequency trends across the procurement landscape.\nComponent Owner: Chang Fang Yu\nInteractive Controls Unified control panel with filters for date ranges, agencies, suppliers, tender types and award amounts.\n\n\n\n\n\nReal-time Procurement Trends : Visualisation of temporal spending patterns including month-over-month changes, year-over-year comparisons, and identification of peak procurement periods tied to budget cycles.\nAgency-Level Procurement Analysis : Identification of top spending agencies with their specialization patterns. Enable comparative analysis to spot unusual procurement behaviors and spending anomalies.\nSupplier Market Presence : Track key suppliers, awarded contracts, and market concentration.\nMarket Share & Competitive : Evaluate supplier dominance, competition, and procurement fairness across agencies.\n\n\n\n\n\n\n\n\n\n\nA network graph visualization will be developed to illustrate the relationships between government agencies and suppliers based on procurement transactions.  \n\n\n\n\nInteractive network visualisation (core) \nFiltering and control panel (core) \nNetwork metrics dashboard (core) \nCommunity detection \nEntity focus view \n\n\n\n\n\nAgency-supplier collaboration: which agencies work most frequently with specific suppliers \nNetwork centrality analysis: Identify central nodes in procurement networks \nCommunity detection: will reveal clusters of agencies and suppliers that frequently collaborate."
  },
  {
    "objectID": "Proposal/proposal.html#prototype",
    "href": "Proposal/proposal.html#prototype",
    "title": "Project Proposal",
    "section": "",
    "text": "Tender ClassificationProcurement DashboardNetwork Analysis\n\n\nTo update\n\n\n\n\n\n\n\nNetwork visualisation \nCommunity detection \nNetwork metrics"
  },
  {
    "objectID": "meetings/meeting_notes_3.html",
    "href": "meetings/meeting_notes_3.html",
    "title": "Meeting Minutes 3",
    "section": "",
    "text": "The meeting notes below document the 3rd discussion among group members and consultation with Professor Kam.\n\nDate: 2pm, March 8, 2025\n\n\nAttendees: Cathy, Fangyu\n\n\nProgress updates\n1 Text Analysis Development\n\nFangyu has made progress on several fronts \n\nDeveloped a Shiny App prototype specifically for word cloud visualisation.\nInitiated text analysis of procurement tender descriptions.\nConducted experimental LDA (Latent Dirichlet Allocation) analysis to explore text analysis possibilities with the procurement data.\n\n\n2 Interface Design Progress \n\nCathy has begun work on user interface design:  \n\nCreated initial sketch designs for the Network analysis module \nDeveloped preliminary layouts for the Overview dashboard \nExpressed uncertainty about whether the current design direction is logistically workable. \n\n\nAction Item \n\nCathy will join the Github to begin development. \nCathy will work on drafting a proposal for the procurement data module and further develop the Network Module story board. \nFangyu will continue iterating on the Shiny App prototype and refine LDA analysis. \nGroup will consult Prof. Kam to clear questions."
  },
  {
    "objectID": "meetings/meeting_notes_1.html",
    "href": "meetings/meeting_notes_1.html",
    "title": "Meeting Minutes 1",
    "section": "",
    "text": "The meeting notes below document the 2nd discussion among group members.\n\nDate: 2pm, March 3, 2025\n\n\nAttendees: Cathy, Fangyu\n\n\nDiscussion\n1 Readiness of Github Collaboration and Netilify Page\n\nFangyu has initiated the Github repo and Netlify for the project.\n\n2 Survey Data Analysis Options\n\nCathy noted that PISA data offers multiple analytical perspectives.\n\nPISA data enables broader analytical exploration but requires more extensive data exploration and processing \nNetwork analysis also appears to be an interesting topic, but is new to this field. \nExpressed uncertainty about the viability of Nowcasting as a project direction.\n\n\n3 Data Complexity Considerations\n\nFangyu highlighted concerns regarding:  \n\nThe complexity of processing survey data, particularly due to encoding requirements \nWeather data’s suitability for forecasting applications \nPreference for selecting a topic with stronger business value implications \nPlans to consult with Professor regarding Open Government Data options  \n\n\n4 Text Analysis Approach\n\nFangyu proposed leveraging text analysis techniques specifically for Word Cloud visualizations of the procurement data. \n\nBoth Cathy and Fangyu decided to explore two alternative topics: \n\nGovernment Procurement \nNowcasting \n\nAction Items \n\nCathy will start developing a comprehensive storyboard for the Network analysis module. \nFangyu will begin text analysis implementation and create an initial prototype."
  },
  {
    "objectID": "Data_Preprocessing/Data_Preprocessing_LDA.html",
    "href": "Data_Preprocessing/Data_Preprocessing_LDA.html",
    "title": "Data Preprocessing for LDA",
    "section": "",
    "text": "This document details the data preprocessing steps for analyzing Singapore’s government procurement data. The process includes data cleaning, text normalization, and preparation for subsequent analyses such as LDA topic modeling and network analysis."
  },
  {
    "objectID": "Data_Preprocessing/Data_Preprocessing_LDA.html#overview",
    "href": "Data_Preprocessing/Data_Preprocessing_LDA.html#overview",
    "title": "Data Preprocessing for LDA",
    "section": "",
    "text": "This document details the data preprocessing steps for analyzing Singapore’s government procurement data. The process includes data cleaning, text normalization, and preparation for subsequent analyses such as LDA topic modeling and network analysis."
  },
  {
    "objectID": "Data_Preprocessing/Data_Preprocessing_LDA.html#data-preprocessing-steps",
    "href": "Data_Preprocessing/Data_Preprocessing_LDA.html#data-preprocessing-steps",
    "title": "Data Preprocessing for LDA",
    "section": "Data Preprocessing Steps",
    "text": "Data Preprocessing Steps\n\n1. Data Import and Initial Setup\nFirst, we load the necessary libraries and import the raw data:\n\nlibrary(readr)\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse, plotly, \n               DT, GGally, parallelPlot, tidytext) \npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\nWe then import the government procurement dataset:\n\nGP &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/GovernmentProcurementviaGeBIZ.csv\")\n\n\n\n2. Initial Data Exploration\n\nData Structure Analysis\n\nglimpse(GP)\n\nRows: 18,638\nColumns: 7\n$ tender_no            &lt;chr&gt; \"ACR000ETT18300010\", \"ACR000ETT18300011\", \"ACR000…\n$ tender_description   &lt;chr&gt; \"SUPPLY, DESIGN, DEVELOPMENT, CUSTOMIZATION, DELI…\n$ agency               &lt;chr&gt; \"Accounting And Corporate Regulatory Authority\", …\n$ award_date           &lt;chr&gt; \"11/6/2019\", \"10/5/2019\", \"30/4/2019\", \"29/8/2019…\n$ tender_detail_status &lt;chr&gt; \"Awarded to Suppliers\", \"Awarded to No Suppliers\"…\n$ supplier_name        &lt;chr&gt; \"AZAAS PTE. LTD.\", \"Unknown\", \"ACCENTURE SG SERVI…\n$ awarded_amt          &lt;dbl&gt; 2305880.0, 0.0, 2035000.0, 30700373.9, 178800.0, …\n\n\n\n\nMissing Values Assessment\n\nsum(is.na(GP))\n\n[1] 0\n\n\n\n\nStatistical Overview\n\nsummary(GP)\n\n  tender_no         tender_description    agency           award_date       \n Length:18638       Length:18638       Length:18638       Length:18638      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n tender_detail_status supplier_name       awarded_amt       \n Length:18638         Length:18638       Min.   :0.000e+00  \n Class :character     Class :character   1st Qu.:7.000e+03  \n Mode  :character     Mode  :character   Median :1.647e+05  \n                                         Mean   :5.540e+06  \n                                         3rd Qu.:8.227e+05  \n                                         Max.   :1.493e+09  \n\n\n\n\nData Fields Examination\n\ncolnames(GP)\n\n[1] \"tender_no\"            \"tender_description\"   \"agency\"              \n[4] \"award_date\"           \"tender_detail_status\" \"supplier_name\"       \n[7] \"awarded_amt\"         \n\n\n\n\nTender Status Analysis\n\n# Check different values in tender_detail_status column\ndistinct_statuses &lt;- GP %&gt;%\n  distinct(tender_detail_status) %&gt;%\n  pull(tender_detail_status)\n\nprint(distinct_statuses)\n\n[1] \"Awarded to Suppliers\"      \"Awarded to No Suppliers\"  \n[3] \"Awarded by Items\"          \"Award by interface record\"\n\n\n\n\n\n3. Data Cleaning Process\n\nInitial Data Filtering\n\n# Exclude invalid tenders\nbefore_count &lt;- nrow(GP)\nCleaned_GP &lt;- GP %&gt;%\n  filter(tender_detail_status %in% c(\"Awarded to Suppliers\", \"Awarded by Items\", \"Award by interface record\"))\nafter_count &lt;- nrow(Cleaned_GP)\n\nprint(paste(\"Original number of tenders:\", before_count))\n\n[1] \"Original number of tenders: 18638\"\n\nprint(paste(\"Number of tenders after cleaning:\", after_count))\n\n[1] \"Number of tenders after cleaning: 17855\"\n\n\n\n\nSaving Initial Cleaned Data\n\nwrite_csv(Cleaned_GP, \"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP.csv\")\nCleaned_GP_check &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP.csv\")\nhead(Cleaned_GP_check)\n\n# A tibble: 6 × 7\n  tender_no         tender_description    agency award_date tender_detail_status\n  &lt;chr&gt;             &lt;chr&gt;                 &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;               \n1 ACR000ETT18300010 SUPPLY, DESIGN, DEVE… Accou… 11/6/2019  Awarded to Suppliers\n2 ACR000ETT19300001 PROVISION OF CONSULT… Accou… 30/4/2019  Awarded to Suppliers\n3 ACR000ETT19300002 SUPPLY, DELIVERY, DE… Accou… 29/8/2019  Awarded to Suppliers\n4 ACR000ETT19300003 PROVISION OF MEDIA M… Accou… 6/8/2019   Awarded to Suppliers\n5 ACR000ETT19300004 INVITATION TO TENDER… Accou… 5/11/2019  Awarded to Suppliers\n6 ACR000ETT20300002 INVITATION TO TENDER… Accou… 10/11/2020 Awarded by Items    \n# ℹ 2 more variables: supplier_name &lt;chr&gt;, awarded_amt &lt;dbl&gt;\n\n\n\n\n\n4. Text Processing and Analysis\n\nTender Description Standardization\n\nlibrary(tidyverse)\n\nCleaned_GP &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP.csv\")\n\n# Text standardization\nCleaned_GP &lt;- Cleaned_GP %&gt;%\n  mutate(tender_description = tolower(tender_description))\n\n# Variation analysis\ntender_variations &lt;- Cleaned_GP %&gt;%\n  group_by(tender_no) %&gt;%\n  summarise(n_unique_desc = n_distinct(tender_description), .groups = \"drop\") %&gt;%\n  filter(n_unique_desc &gt; 1)\n\ntender_detail_variations &lt;- Cleaned_GP %&gt;%\n  filter(tender_no %in% tender_variations$tender_no) %&gt;%\n  arrange(tender_no)\n\nwrite_csv(tender_detail_variations, \"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/tender_description_variations.csv\")\n\nprint(paste(\"Found\", nrow(tender_variations), \"tender_no with different tender_descriptions\"))\n\n[1] \"Found 0 tender_no with different tender_descriptions\"\n\nhead(tender_detail_variations)\n\n# A tibble: 0 × 7\n# ℹ 7 variables: tender_no &lt;chr&gt;, tender_description &lt;chr&gt;, agency &lt;chr&gt;,\n#   award_date &lt;chr&gt;, tender_detail_status &lt;chr&gt;, supplier_name &lt;chr&gt;,\n#   awarded_amt &lt;dbl&gt;\n\n\n\n\nAdvanced Text Cleaning\n\nlibrary(stringr)\n\nCleaned_GP &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/cleaned_GP.csv\")\n\n# Comprehensive text cleaning\nCleaned_GP &lt;- Cleaned_GP %&gt;%\n  mutate(\n    tender_description = tolower(tender_description),\n    tender_description = str_squish(tender_description),\n    tender_description = str_replace_all(tender_description, \"[[:punct:]]\", \"\"),\n    tender_description = str_replace_all(tender_description, \"[^[:alnum:]\\\\s]\", \"\")\n  )\n\ntender_variation_check &lt;- Cleaned_GP %&gt;%\n  group_by(tender_no) %&gt;%\n  summarise(unique_desc = unique(tender_description), .groups = \"drop\") %&gt;%\n  filter(length(unique_desc) &gt; 1)\n\nwrite_csv(Cleaned_GP, \"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_cleaned.csv\")\nprint(nrow(tender_variation_check))\n\n[1] 11658\n\n\n\n\n\n5. Duplicate Analysis and Resolution\n\nIdentifying Duplicates\n\nCleaned_GP &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_cleaned.csv\")\n\nduplicate_descriptions &lt;- Cleaned_GP %&gt;%\n  group_by(tender_description) %&gt;%\n  summarise(n_tenders = n(), unique_tenders = n_distinct(tender_no), .groups = \"drop\") %&gt;%\n  filter(n_tenders &gt; 1)\n\nprint(paste(\"Found\", nrow(duplicate_descriptions), \"duplicate tender_descriptions\"))\n\n[1] \"Found 1742 duplicate tender_descriptions\"\n\nhead(duplicate_descriptions)\n\n# A tibble: 6 × 3\n  tender_description                                    n_tenders unique_tenders\n  &lt;chr&gt;                                                     &lt;int&gt;          &lt;int&gt;\n1 1  1 year term contract for rectification works to e…         2              1\n2 1 courier services to transport covid19 samples swab…         2              1\n3 1 thermal transfer printer labels a rfid compatibili…         2              1\n4 1 this itt is structured to be awarded as a period c…         4              1\n5 1 year term contract for provision of 1 number of me…         4              1\n6 11 year term contract for minor civil engineering wo…         2              1\n\ndetailed_duplicates &lt;- Cleaned_GP %&gt;%\n  filter(tender_description %in% duplicate_descriptions$tender_description) %&gt;%\n  arrange(tender_description, tender_no)\n\nwrite_csv(detailed_duplicates, \"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/tender_description_duplicates.csv\")\nhead(detailed_duplicates)\n\n# A tibble: 6 × 7\n  tender_no         tender_description    agency award_date tender_detail_status\n  &lt;chr&gt;             &lt;chr&gt;                 &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;               \n1 JTC000ETT22000128 1  1 year term contr… Juron… 19/5/2023  Awarded by Items    \n2 JTC000ETT22000128 1  1 year term contr… Juron… 19/5/2023  Awarded by Items    \n3 NST000ETT21000096 1 courier services t… Agenc… 30/11/2021 Awarded by Items    \n4 NST000ETT21000096 1 courier services t… Agenc… 30/11/2021 Awarded by Items    \n5 NST000ETT21000084 1 thermal transfer p… Agenc… 2/11/2021  Awarded by Items    \n6 NST000ETT21000084 1 thermal transfer p… Agenc… 2/11/2021  Awarded by Items    \n# ℹ 2 more variables: supplier_name &lt;chr&gt;, awarded_amt &lt;dbl&gt;"
  },
  {
    "objectID": "Data_Preprocessing/Data_Preprocessing_LDA.html#final-data-preparation",
    "href": "Data_Preprocessing/Data_Preprocessing_LDA.html#final-data-preparation",
    "title": "Data Preprocessing for LDA",
    "section": "Final Data Preparation",
    "text": "Final Data Preparation\n\nData Cleaning Summary\nThe data cleaning process revealed multiple instances of duplicate records in the dataset. These duplicates primarily arose from:\n\nMultiple suppliers being awarded portions of the same tender\nVariations in tender descriptions for the same tender number\nSystem-generated duplicate entries\n\nFor LDA topic modeling, we needed to ensure each tender was represented only once to prevent bias in the word frequency distributions. Therefore, we:\n\nKept only the first occurrence of each unique tender_no and tender_description combination\nStandardized all text data through comprehensive cleaning\nPrepared separate datasets for different analysis purposes\n\n\n\nOutput Datasets\n\nCleaned_GP_LDA.csv\n\nCGC &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_cleaned.csv\")\n\nCleaned_GP_LDA &lt;- CGC %&gt;%\n  distinct(tender_no, tender_description, .keep_all = TRUE)\n\nwrite_csv(Cleaned_GP_LDA, \"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_LDA.csv\")\n\nprint(paste(\"Original rows:\", nrow(Cleaned_GP)))\n\n[1] \"Original rows: 17855\"\n\nprint(paste(\"Final rows:\", nrow(Cleaned_GP_LDA)))\n\n[1] \"Final rows: 11658\"\n\n\n\n\nFinal Validation\n\nCleaned_GP_LDA &lt;- read_csv(\"C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_LDA.csv\")\n\nduplicate_check &lt;- Cleaned_GP_LDA %&gt;%\n  group_by(tender_no, tender_description) %&gt;%\n  summarise(count = n(), .groups = \"drop\") %&gt;%\n  filter(count &gt; 1)\n\nif (nrow(duplicate_check) == 0) {\n  print(\"✅ No duplicate tender_no + tender_description found. The data cleaning is correct!\")\n} else {\n  print(paste(\"⚠️ Found\", nrow(duplicate_check), \"duplicate records. Check the data again!\"))\n  head(duplicate_check)\n}\n\n[1] \"✅ No duplicate tender_no + tender_description found. The data cleaning is correct!\"\n\nprint(paste(\"Original dataset rows:\", 17855))\n\n[1] \"Original dataset rows: 17855\"\n\nprint(paste(\"After cleaning, remaining rows:\", nrow(Cleaned_GP_LDA)))\n\n[1] \"After cleaning, remaining rows: 11658\"\n\n\n\n\n\nFinal Dataset Preview\n\nhead(Cleaned_GP_LDA)\n\n# A tibble: 6 × 7\n  tender_no         tender_description    agency award_date tender_detail_status\n  &lt;chr&gt;             &lt;chr&gt;                 &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;               \n1 ACR000ETT18300010 supply design develo… Accou… 11/6/2019  Awarded to Suppliers\n2 ACR000ETT19300001 provision of consult… Accou… 30/4/2019  Awarded to Suppliers\n3 ACR000ETT19300002 supply delivery desi… Accou… 29/8/2019  Awarded to Suppliers\n4 ACR000ETT19300003 provision of media m… Accou… 6/8/2019   Awarded to Suppliers\n5 ACR000ETT19300004 invitation to tender… Accou… 5/11/2019  Awarded to Suppliers\n6 ACR000ETT20300002 invitation to tender… Accou… 10/11/2020 Awarded by Items    \n# ℹ 2 more variables: supplier_name &lt;chr&gt;, awarded_amt &lt;dbl&gt;\n\n\n\n\nData Preparation for LDA Topic Modeling Flow"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Let’s Track Public Dollars!",
    "section": "",
    "text": "Are you curious about how Singapore government spends public funds across agencies, suppliers, and projects?\nYou’re at the right place! This interactive Shiny dashboard provides data-driven insights into government procurement patterns from 2019 to 2023, helping to enhance transparency, efficiency, and strategic decision-making in public spending.\nThrough this dashboard, you can explore real-time procurement trends and spending patterns, analyse relationships between government agencies and suppliers, evaluate market competition and supplier diversity, and discover insights from procurement descriptions through text analysis.\nStart exploring by selecting a module from the menu on the left."
  },
  {
    "objectID": "index.html#what-youll-discover",
    "href": "index.html#what-youll-discover",
    "title": "Let’s Track Public Dollars!",
    "section": "What You’ll Discover",
    "text": "What You’ll Discover\nOur analysis of procurement data reveals patterns across agencies, suppliers, and time periods that might otherwise remain hidden in complex datasets. Through this dashboard, you can:\n\nTrack real-time procurement trends and spending patterns\nIdentify key relationships between government agencies and suppliers\nEvaluate market competition and supplier diversity\nUncover insights from procurement descriptions through text analysis\n\nThis website is created for Visual Analytics course project at Singapore Management University."
  },
  {
    "objectID": "meetings/meeting_notes_2.html",
    "href": "meetings/meeting_notes_2.html",
    "title": "Meeting Minutes 2",
    "section": "",
    "text": "The meeting notes below document the 2nd discussion among group members.\n\nDate: 9pm, March 6, 2025\n\n\nAttendees: Cathy, Fangyu\n\n\nDiscussion\n1 Nowcasting Data Requirements\n\nFangyu consulted on Piazza about nowcasting data frequency requirements, noting that most government datasets only update quarterly or annually, with approximately five datasets updating monthly. \n[Prof. Kam clarified that best practices for nowcasting require monthly data updates.\nBased on data availability constraints, Fangyu suggested Network analysis as a more feasible research direction. \n\n2 Procurement Data Analysis Opportunities\n\nCathy proposed that government procurement data could support multiple analysis approaches beyond Network analysis, including:  \n\nTemporal analysis to identify trends and patterns over time \nText analysis of tender descriptions for insights (including Word Cloud visualization) \n\n\n3 Text Analysis Approach\n\nFangyu proposed leveraging text analysis techniques specifically for Word Cloud visualisations of the procurement data. \n\nTeam agreed with the proposals and will work on the following action items. \n4 Action Items \n\nCathy will start developing a comprehensive storyboard for the Network analysis module. \nFangyu will begin text analysis implementation and create an initial prototype."
  },
  {
    "objectID": "meetings/meeting_notes_4.html",
    "href": "meetings/meeting_notes_4.html",
    "title": "Meeting Minutes 4",
    "section": "",
    "text": "The meeting notes below document the 3rd discussion among group members and consultation with Professor Kam.\n\nDate: 4pm, March 11, 2025\n\n\nAttendees: Cathy, Fangyu, Prof. Kam\n\n\nDiscussion\n1 Procurement Dashboard & Visualization\n\nCathy presented the proposal outline and storyboard for the Procurement dashboard and Network analysis.\nProf. Kam’s feedback\n\nImplement user flexibility to select the top N number of agencies/suppliers when visualizing dashboard data.\nCreate interactive bar charts where users can click on specific agencies/suppliers to trigger dynamic metrics tables with relevant information, rather than displaying static tables.\nReplace individual month selectors with calendar selectors or quarterly options (Q1, Q2, etc.) to better represent ordinal data and reveal seasonal patterns.\nUtilise Treemaps to visualize agency hierarchy by ministry, enabling better drill-down functionality. Add interactivity to display additional information, such as the top five suppliers for any selected agency.\n\n\n2 Network Graph Visualization\n\nCathy presented the three-tab design concept for the procurement network dashboards.\nProf. Kam’s feedback\n\nCalculate node centrality metrics first to enable community construction. These centrality indices will provide critical analytical information for outcomes.\nImplement user selection of centrality measurement types, allowing the network graph to update based on the selected method.\nIntegrate community detection/analysis within the initial “Visualisation” tab, followed by deeper analysis based on community findings.\n[Note: Cathy inquired if community detection could remain as a standalone tab. Prof. Kam recommended further exploration before making this decision.]\n\n\n3 Text Analysis & Topic Modeling\n\nFangyu demonstrated the text analysis storyboard and current progress, including the LDA (Latent Dirichlet Allocation) topic modeling and clustering techniques used to identify key procurement themes.\nProf. Kam’s feedback\n\nEmphasized the importance of interactive data refinement to continuously improve classification accuracy.\nRecommended training a model to label each tender type, referencing the book “Text Modeling with R” to establish a standardized categorization process.\nSuggested revised approaches for LDA modeling utilizing TF-IDF (Term Frequency-Inverse Document Frequency) metrics while maintaining the tidytext approach.\nProposed re-ordering the tabs within the module: Learning Data &gt; Word Cloud &gt; Text Analysis &gt; LDA Text Modeling (since LDA itself is a clustering analysis for classification).\nRecommended restructuring the overall module flow: Begin with Text Analysis to derive tender classification results &gt; Incorporate these results into Network Analysis to generate more insightful visualizations.\n\n\n4 Additional Notes (Text Analysis Techniques):\n\nTF-IDF (Term Frequency-Inverse Document Frequency): Identifies the most representative keywords to enhance topic modeling accuracy.\nText Cleaning: Ensures clean textual data (removing stop words, special characters, punctuation, etc.) for higher-quality analysis.\nLDA Refinement Process: The LDA model should be iteratively refined to achieve the purest possible categorization, enhancing the clarity and accuracy of procurement descriptions.\n\nShiny App Development & Integration\n\nTeam had questions about code compilation and implementing a sophisticated Shiny app interface similar to previous student work.\nProf Kam’s feedback\n\nTeam members should develop modules separately but eventually compile all code into a single Shiny web app file for publication on Shinyapps.io (one link only to be used on Netlify).\nBefore code compilation, the team must agree on a consistent menu design across all modules to ensure consistent rendering and expected results.\n\n\n5 Next steps\n\nFangYu to continue refining the text classification module implementing Prof. Kam’s recommended approaches by the next milestone.\nCathy to redesign the interactive procurement network visualization incorporating feedback on centrality metrics and community detection.\n\n\n\nSchedule another consultation with Prof. Kam at the next project milestone to review progress."
  },
  {
    "objectID": "shinyapp/LDA.html",
    "href": "shinyapp/LDA.html",
    "title": "LDA",
    "section": "",
    "text": "library(tidyverse)\n\nWarning: package 'tidyverse' was built under R version 4.4.3\n\n\nWarning: package 'ggplot2' was built under R version 4.4.3\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tm)\n\nWarning: package 'tm' was built under R version 4.4.3\n\n\nLoading required package: NLP\n\nAttaching package: 'NLP'\n\nThe following object is masked from 'package:ggplot2':\n\n    annotate\n\nlibrary(topicmodels)\n\nWarning: package 'topicmodels' was built under R version 4.4.3\n\nlibrary(tidytext)\n\nWarning: package 'tidytext' was built under R version 4.4.3\n\n# 讀取資料\nCleaned_GP_LDA &lt;- read_csv(\"data/Cleaned_GP_LDA.csv\")\n\nRows: 11658 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): tender_no, tender_description, agency, award_date, tender_detail_st...\ndbl (1): awarded_amt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nCleaned_GP &lt;- read_csv(\"data/Cleaned_GP.csv\") %&gt;%\n  select(tender_no, award_date, awarded_amt, tender_detail_status)\n\nRows: 17855 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): tender_no, tender_description, agency, award_date, tender_detail_st...\ndbl (1): awarded_amt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# 定義停用詞\ndefault_stopwords &lt;- c(stopwords(\"en\"), \"please\", \"refer\", \"another\", \"one\", \"two\", \"three\", \n                       \"framework\", \"edition\", \"related\", \"whole\", \"period\", \"government\", \n                       \"entities\", \"various\", \"including\", \"requirement\", \"provide\", \"supply\", \n                       \"service\", \"procurement\", \"year\", \"option\", \"extend\", \"agreement\", \n                       \"singapore\", \"Singapore\")\n\n# 清理文字\nCleaned_GP_LDA &lt;- Cleaned_GP_LDA %&gt;%\n  mutate(\n    tender_clean = tender_description %&gt;%\n      tolower() %&gt;%\n      removePunctuation() %&gt;%\n      removeNumbers() %&gt;%\n      stripWhitespace() %&gt;%\n      removeWords(default_stopwords)\n  )\n\n# 建立 DTM\ndtm &lt;- Cleaned_GP_LDA %&gt;%\n  unnest_tokens(word, tender_clean) %&gt;%\n  count(tender_no, word) %&gt;%\n  cast_dtm(document = tender_no, term = word, value = n)\n\n# 訓練 LDA 模型\nlda_model &lt;- LDA(dtm, k = 7, control = list(seed = 1234))\n\n# 取得分類\nlda_assignments &lt;- tidy(lda_model, matrix = \"gamma\") %&gt;%\n  group_by(document) %&gt;%\n  top_n(1, gamma) %&gt;%\n  ungroup()\n\n# 對應主題編號為分類名稱\nlda_category_map &lt;- function(topic) {\n  case_when(\n    topic == 1 ~ \"General Procurement - Goods\",\n    topic == 2 ~ \"General Procurement - Services\",\n    topic == 3 ~ \"Engineering Procurement - Goods\",\n    topic == 4 ~ \"Engineering Procurement - Services\",\n    topic == 5 ~ \"Engineering Procurement - EPC\",\n    topic == 6 ~ \"PPP Procurement - DBO\",\n    topic == 7 ~ \"PPP Procurement - DBFO\",\n    TRUE ~ \"Unclassified\"\n  )\n}\n\n# 合併回原始 Cleaned_GP_LDA\nCleaned_GP_LDA_LDA &lt;- Cleaned_GP_LDA %&gt;%\n  left_join(lda_assignments, by = c(\"tender_no\" = \"document\")) %&gt;%\n  mutate(LDA_Category = lda_category_map(topic))\n\n# 合併 Cleaned_GP（含金額與日期）\nCleaned_GP_Final &lt;- Cleaned_GP %&gt;%\n  mutate(\n    tender_date = as.Date(award_date, format = \"%d/%m/%Y\"),\n    tender_value = as.numeric(gsub(\"[^0-9.]\", \"\", awarded_amt))\n  ) %&gt;%\n  left_join(Cleaned_GP_LDA_LDA %&gt;% select(tender_no, LDA_Category), by = \"tender_no\") %&gt;%\n  filter(!is.na(tender_date), !is.na(tender_value), !is.na(LDA_Category))\n\n# 儲存結果\nwrite_csv(Cleaned_GP_Final, \"data/default_dataset_tender_market_analysis.csv\")\n\ncat(\"✅ default_dataset_tender_market_analysis.csv 已成功建立。\\n\")\n\n✅ default_dataset_tender_market_analysis.csv 已成功建立。\n\n\n\nresult &lt;- read_csv(\"data/default_dataset_tender_market_analysis.csv\")\n\nRows: 17855 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (4): tender_no, award_date, tender_detail_status, LDA_Category\ndbl  (2): awarded_amt, tender_value\ndate (1): tender_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nglimpse(result)\n\nRows: 17,855\nColumns: 7\n$ tender_no            &lt;chr&gt; \"ACR000ETT18300010\", \"ACR000ETT19300001\", \"ACR000…\n$ award_date           &lt;chr&gt; \"11/6/2019\", \"30/4/2019\", \"29/8/2019\", \"6/8/2019\"…\n$ awarded_amt          &lt;dbl&gt; 2305880.00, 2035000.00, 30700373.87, 178800.00, 8…\n$ tender_detail_status &lt;chr&gt; \"Awarded to Suppliers\", \"Awarded to Suppliers\", \"…\n$ tender_date          &lt;date&gt; 2019-06-11, 2019-04-30, 2019-08-29, 2019-08-06, …\n$ tender_value         &lt;dbl&gt; 2305880.00, 2035000.00, 30700373.87, 178800.00, 8…\n$ LDA_Category         &lt;chr&gt; \"PPP Procurement - DBO\", \"Engineering Procurement…\n\n\n\nCleaned_GP_LDA &lt;- read_csv(\"data/Cleaned_GP_LDA.csv\")\n\nRows: 11658 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): tender_no, tender_description, agency, award_date, tender_detail_st...\ndbl (1): awarded_amt\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nCleaned_GP_LDA\n\n# A tibble: 11,658 × 7\n   tender_no         tender_description   agency award_date tender_detail_status\n   &lt;chr&gt;             &lt;chr&gt;                &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;               \n 1 ACR000ETT18300010 supply design devel… Accou… 11/6/2019  Awarded to Suppliers\n 2 ACR000ETT19300001 provision of consul… Accou… 30/4/2019  Awarded to Suppliers\n 3 ACR000ETT19300002 supply delivery des… Accou… 29/8/2019  Awarded to Suppliers\n 4 ACR000ETT19300003 provision of media … Accou… 6/8/2019   Awarded to Suppliers\n 5 ACR000ETT19300004 invitation to tende… Accou… 5/11/2019  Awarded to Suppliers\n 6 ACR000ETT20300002 invitation to tende… Accou… 10/11/2020 Awarded by Items    \n 7 ACR000ETT20300003 provision of an it … Accou… 9/12/2020  Awarded to Suppliers\n 8 ACR000ETT20300004 conceptualization d… Accou… 9/3/2021   Awarded to Suppliers\n 9 ACR000ETT21000001 design development … Accou… 6/9/2021   Awarded to Suppliers\n10 ACR000ETT21000003 supply delivery ins… Accou… 14/4/2022  Awarded to Suppliers\n# ℹ 11,648 more rows\n# ℹ 2 more variables: supplier_name &lt;chr&gt;, awarded_amt &lt;dbl&gt;\n\n\n\nlibrary(DiagrammeR)\n\nWarning: package 'DiagrammeR' was built under R version 4.4.3\n\ngrViz(\"\ndigraph LDA_Preparation {\n  graph [layout = dot, rankdir = TB]\n  node [shape = rect, style = filled, color = gray90, fontname = Helvetica]\n\n  Start [shape = circle, label = '', width = 0.3, color = black, fillcolor = black]\n  End [shape = circle, label = '', width = 0.3, color = black, fillcolor = black]\n\n  Start -&gt; A1\n  A1 [label = 'Load raw data (CSV)']\n  A1 -&gt; A2\n  A2 [label = 'Inspect structure using glimpse()']\n  A2 -&gt; A3\n  A3 [label = 'Filter for awarded tenders only']\n  A3 -&gt; A4\n  A4 [label = 'Lowercase tender_description']\n  A4 -&gt; A5\n  A5 [label = 'Group by tender_no and check distinct descriptions']\n  A5 -&gt; A6\n  A6 [label = 'Filter for distinct tender no. and tender description']\n  A6 -&gt; A7\n  A7 [label = 'Clean special characters, symbols, punctuation']\n  A7 -&gt; A8\n  A8 [label = 'Remove stop words and unnecessary text']\n  A8 -&gt; A9\n  A9 [label = 'Tokenize and lemmatize description']\n  A9 -&gt; A10\n  A10 [label = 'Recombine cleaned words into final string']\n  A10 -&gt; A11\n  A11 [label = 'Write cleaned data to Cleaned_GP_LDA.csv']\n  A11 -&gt; End\n}\n\")"
  },
  {
    "objectID": "Poster.html",
    "href": "Poster.html",
    "title": "Project Poster",
    "section": "",
    "text": "Image"
  }
]