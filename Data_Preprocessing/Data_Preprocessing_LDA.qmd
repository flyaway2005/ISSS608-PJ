---
title: "Data Preprocessing for LDA"
author: "Chang Fang Yu"
date-modified: "last-modified"
execute:
  echo: True
  eval: True
  warning: false
  freeze: true
---

## Overview

This document details the data preprocessing steps for analyzing Singapore's government procurement data. The process includes data cleaning, text normalization, and preparation for subsequent analyses such as LDA topic modeling and network analysis.

## Data Preprocessing Steps

### 1. Data Import and Initial Setup

First, we load the necessary libraries and import the raw data:

```{r}
library(readr)
```

```{r}
pacman::p_load(ggrepel, patchwork, 
               ggthemes, hrbrthemes,
               tidyverse, plotly, 
               DT, GGally, parallelPlot, tidytext) 
pacman::p_load(igraph, tidygraph, ggraph, 
               visNetwork, lubridate, clock,
               tidyverse, graphlayouts)
```

We then import the government procurement dataset:

```{r}
GP <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/GovernmentProcurementviaGeBIZ.csv")
```

### 2. Initial Data Exploration

#### Data Structure Analysis

```{R}
glimpse(GP)
```

#### Missing Values Assessment

```{R}
sum(is.na(GP))
```

#### Statistical Overview

```{R}
summary(GP)
```

#### Data Fields Examination

```{r}
colnames(GP)
```

#### Tender Status Analysis

```{r}
# Check different values in tender_detail_status column
distinct_statuses <- GP %>%
  distinct(tender_detail_status) %>%
  pull(tender_detail_status)

print(distinct_statuses)
```

### 3. Data Cleaning Process

#### Initial Data Filtering

```{r}
# Exclude invalid tenders
before_count <- nrow(GP)
Cleaned_GP <- GP %>%
  filter(tender_detail_status %in% c("Awarded to Suppliers", "Awarded by Items", "Award by interface record"))
after_count <- nrow(Cleaned_GP)

print(paste("Original number of tenders:", before_count))
print(paste("Number of tenders after cleaning:", after_count))
```

#### Saving Initial Cleaned Data

```{r}
write_csv(Cleaned_GP, "C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP.csv")
Cleaned_GP_check <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP.csv")
head(Cleaned_GP_check)
```

### 4. Text Processing and Analysis

#### Tender Description Standardization

```{R}
library(tidyverse)

Cleaned_GP <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP.csv")

# Text standardization
Cleaned_GP <- Cleaned_GP %>%
  mutate(tender_description = tolower(tender_description))

# Variation analysis
tender_variations <- Cleaned_GP %>%
  group_by(tender_no) %>%
  summarise(n_unique_desc = n_distinct(tender_description), .groups = "drop") %>%
  filter(n_unique_desc > 1)

tender_detail_variations <- Cleaned_GP %>%
  filter(tender_no %in% tender_variations$tender_no) %>%
  arrange(tender_no)

write_csv(tender_detail_variations, "C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/tender_description_variations.csv")

print(paste("Found", nrow(tender_variations), "tender_no with different tender_descriptions"))
head(tender_detail_variations)
```

#### Advanced Text Cleaning

```{r}
library(stringr)

Cleaned_GP <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/cleaned_GP.csv")

# Comprehensive text cleaning
Cleaned_GP <- Cleaned_GP %>%
  mutate(
    tender_description = tolower(tender_description),
    tender_description = str_squish(tender_description),
    tender_description = str_replace_all(tender_description, "[[:punct:]]", ""),
    tender_description = str_replace_all(tender_description, "[^[:alnum:]\\s]", "")
  )

tender_variation_check <- Cleaned_GP %>%
  group_by(tender_no) %>%
  summarise(unique_desc = unique(tender_description), .groups = "drop") %>%
  filter(length(unique_desc) > 1)

write_csv(Cleaned_GP, "C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_cleaned.csv")
print(nrow(tender_variation_check))
```

### 5. Duplicate Analysis and Resolution

#### Identifying Duplicates

```{r}
Cleaned_GP <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_cleaned.csv")

duplicate_descriptions <- Cleaned_GP %>%
  group_by(tender_description) %>%
  summarise(n_tenders = n(), unique_tenders = n_distinct(tender_no), .groups = "drop") %>%
  filter(n_tenders > 1)

print(paste("Found", nrow(duplicate_descriptions), "duplicate tender_descriptions"))
head(duplicate_descriptions)

detailed_duplicates <- Cleaned_GP %>%
  filter(tender_description %in% duplicate_descriptions$tender_description) %>%
  arrange(tender_description, tender_no)

write_csv(detailed_duplicates, "C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/tender_description_duplicates.csv")
head(detailed_duplicates)
```

## Final Data Preparation

### Data Cleaning Summary

The data cleaning process revealed multiple instances of duplicate records in the dataset. These duplicates primarily arose from:

1.  Multiple suppliers being awarded portions of the same tender
2.  Variations in tender descriptions for the same tender number
3.  System-generated duplicate entries

For LDA topic modeling, we needed to ensure each tender was represented only once to prevent bias in the word frequency distributions. Therefore, we:

1.  Kept only the first occurrence of each unique tender_no and tender_description combination
2.  Standardized all text data through comprehensive cleaning
3.  Prepared separate datasets for different analysis purposes

### Output Datasets

#### Cleaned_GP_LDA.csv

```{r}
CGC <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_cleaned.csv")

Cleaned_GP_LDA <- CGC %>%
  distinct(tender_no, tender_description, .keep_all = TRUE)

write_csv(Cleaned_GP_LDA, "C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_LDA.csv")

print(paste("Original rows:", nrow(Cleaned_GP)))
print(paste("Final rows:", nrow(Cleaned_GP_LDA)))
```

#### Final Validation

```{r}
Cleaned_GP_LDA <- read_csv("C:/Users/irisc/SynologyDrive/Documents/flyaway2005/ISSS608-team4pj/data/Cleaned_GP_LDA.csv")

duplicate_check <- Cleaned_GP_LDA %>%
  group_by(tender_no, tender_description) %>%
  summarise(count = n(), .groups = "drop") %>%
  filter(count > 1)

if (nrow(duplicate_check) == 0) {
  print("✅ No duplicate tender_no + tender_description found. The data cleaning is correct!")
} else {
  print(paste("⚠️ Found", nrow(duplicate_check), "duplicate records. Check the data again!"))
  head(duplicate_check)
}

print(paste("Original dataset rows:", 17855))
print(paste("After cleaning, remaining rows:", nrow(Cleaned_GP_LDA)))
```

### Final Dataset Preview

```{r}
head(Cleaned_GP_LDA)
```

### Data Preparation for LDA Topic Modeling Flow

![](/images/flowchat_datapreparationforLDA.png)
