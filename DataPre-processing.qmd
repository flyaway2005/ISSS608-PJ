---
title: "Data Pre-processing"
author: "Chang Fang Yu, Cathy CHU Shan-hui"
date-modified: "last-modified"
execute:
  echo: False
  eval: True
  warning: false
  freeze: true
---

```{r}
library(readr)
library(tidyverse)
library(lubridate)
library(stringdist)
library(stringr)
```

```{r}
pacman::p_load(ggrepel, patchwork, 
               ggthemes, hrbrthemes,
               tidyverse, plotly, 
               DT, GGally, parallelPlot, tidytext) 
pacman::p_load(igraph, tidygraph, ggraph, 
               visNetwork, lubridate, clock,
               tidyverse, graphlayouts)
```

```{R}
GP <- read_csv("data/GovernmentProcurementviaGeBIZ.csv")
EN <- read_csv("data/SGentities.csv")
```

::: panel-tabset
### GP(GovernmentProcurementviaGeBIZ.csv")

```{R}
library(knitr)

kable(head(GP))

```

### EN(SGentities.csv)

```{r}
kable(head(EN))
```
:::

#### SG Government Engities Data set (EN)

This R script processes a dataset (EN) containing government agency names, where abbreviations are enclosed in parentheses ( ). The goal is to extract these abbreviations into a new column (ABBREVIATION) while keeping a clean version of the agency names (NAME_CLEAN).

```{r}
EN <- EN %>%
  add_row(NAME = "Jurong Town Corporation", CATEGORY = "STATUTORY_BOARDS", SUBCAT = "Urban Planning") %>%
  add_row(NAME = "Assumption Pathway School", CATEGORY = "EDUCATION", SUBCAT = "Specialised Schools") %>%
  add_row(NAME = "Raffles Girls' School (Secondary)", CATEGORY = "EDUCATION", SUBCAT = "Independent Schools") %>%
  add_row(NAME = "Anglo-Chinese School (Independent)", CATEGORY = "EDUCATION", SUBCAT = "Independent Schools") %>%
  add_row(NAME = "Northlight School", CATEGORY = "EDUCATION", SUBCAT = "Specialised Schools")
```

```{r}
library(tidyverse)
library(lubridate)
library(stringdist)
library(stringr)
library(fuzzyjoin)


# 轉換日期格式
GP <- GP %>% mutate(award_date = dmy(award_date))

# 標準化機構名稱，移除括號內的縮寫，清理格式
EN <- EN %>%
  mutate(
    NAME_CLEAN = str_remove(NAME, "\\s*\\(.*?\\)\\s*") %>%
                tolower() %>%
                str_trim() %>%
                str_replace_all("[^a-z0-9 ]", "")  # 移除標點符號
  )

# 填補 SGentities.csv 內部的 SUBCAT 缺失值
EN <- EN %>%
  mutate(SUBCAT = ifelse(is.na(SUBCAT), CATEGORY, SUBCAT))

GP <- GP %>%
  mutate(
    agency_clean = tolower(agency) %>%
                   str_trim() %>%
                   str_replace_all("[^a-z0-9 ]", "")
  )

# 直接匹配名稱
GP <- GP %>%
  left_join(EN, by = c("agency_clean" = "NAME_CLEAN"))

# 找出未匹配的機構名稱
unmatched_indices <- which(is.na(GP$CATEGORY))
unmatched_agencies <- GP$agency_clean[unmatched_indices]

# 使用 fuzzyjoin 進行更強的模糊匹配
gp_unmatched <- tibble(agency_clean = unmatched_agencies)
matches <- stringdist_left_join(gp_unmatched, EN, by = c("agency_clean" = "NAME_CLEAN"), method = "jw", max_dist = 0.3)

# 更新 GP 數據
gp_match_map <- matches %>% select(agency_clean, CATEGORY, SUBCAT) %>% distinct()
GP <- GP %>%
  left_join(gp_match_map, by = "agency_clean", suffix = c("", "_matched")) %>%
  mutate(
    CATEGORY = coalesce(CATEGORY, CATEGORY_matched),
    SUBCAT = coalesce(SUBCAT, SUBCAT_matched, CATEGORY)  
  # 若 SUBCAT 為 NA，則填充 CATEGORY
  ) %>%
  select(-CATEGORY_matched, -SUBCAT_matched)

# 檢查 SGentities.csv 是否本身有 SUBCAT 缺失
print(paste("SUBCAT missing in SGentities after filling:", sum(is.na(EN$SUBCAT))))

# 輸出處理後的數據
write_csv(GP, "Cleaned_Tenders.csv")
write_csv(EN, "Processed_SGentities.csv")

```

```{r}
# 讀取處理後的標案數據
Cleaned_GP <- read_csv("Cleaned_Tenders.csv")

# 查看前幾行
head(Cleaned_GP)

# 檢查 CATEGORY 和 SUBCAT 是否成功匹配
table(is.na(Cleaned_GP$CATEGORY))  # FALSE 代表成功匹配的數量
table(is.na(Cleaned_GP$SUBCAT))

# 檢查某個特定的 agency 是否正確分類
Cleaned_GP %>%
  filter(agency == "Accounting And Corporate Regulatory Authority") %>%
  select(agency, CATEGORY, SUBCAT) %>%
  head()

```

```{r}
# 讀取處理後的機構數據
Processed_EN <- read_csv("Processed_SGentities.csv")

# 查看前幾行
head(Processed_EN)

# 確保縮寫已經從 `NAME` 內移除
Processed_EN %>%
  select(NAME, NAME_CLEAN) %>%
  head()

# 檢查是否有重複的 NAME_CLEAN
sum(duplicated(Processed_EN$NAME_CLEAN))

```

```{r}
# 檢查 CATEGORY 和 SUBCAT 欄位有多少 NA
sum(is.na(GP$CATEGORY))  # 未匹配到 CATEGORY 的總數
sum(is.na(GP$SUBCAT))    # 未匹配到 SUBCAT 的總數

```

**Data Preprocessing Summary and Rationale**

In the data preprocessing stage, several key steps were undertaken to ensure that government procurement data (GP) was properly structured, categorized, and cleaned for analysis:

**Date Standardization**

The award_date column was converted to a standard date format using lubridate::dmy().

Reason: This ensures consistency in time-based analysis, enabling accurate trend identification. Agency Name Cleaning

The agency names in SGentities.csv (EN) were standardized by: Removing abbreviations in parentheses (e.g., "Ministry of Education (MOE)" → "Ministry of Education"). Converting to lowercase. Trimming extra spaces. Removing punctuation and special characters. Reason: Standardized names improve the accuracy of matching between procurement records and agency classifications. Handling Missing SUBCAT Values

If SUBCAT was missing, it was replaced with its corresponding CATEGORY. Reason: Ensures hierarchical classification remains complete and prevents missing values in the dataset. Direct Matching of Agencies

The cleaned agency column in GP was directly matched to NAME_CLEAN in EN using left_join(). Reason: To map each procurement record to its corresponding agency category. Fuzzy Matching for Unmatched Agencies

Agencies that were not matched directly were processed using stringdist_left_join() with Jaro-Winkler distance (max_dist = 0.3). Reason: Accounts for minor spelling variations, ensuring more robust name matching. Final Data Validation and Export

Any remaining missing values in SUBCAT were replaced with CATEGORY. The cleaned datasets were saved as Cleaned_Tenders.csv and Processed_SGentities.csv.

Reason: Ensures that all records are categorized correctly, enabling further analysis and visualization. Final Outcome After preprocessing, all procurement records (GP) were successfully mapped to their respective CATEGORY and SUBCAT. There were no missing values, ensuring a well-structured dataset for machine learning models and visual analysis.

This preprocessing was necessary to:

-   Enable accurate trend analysis and clustering.

-   Ensure hierarchical classification for structured reporting.

-   Improve matching accuracy between procurement records and government entities.

-   Prepare the data for machine learning-based classification and NLP-based insights.

With this cleaned data, the next steps could involve topic modeling (LDA), classification modeling, or interactive dashboard visualization.

Result Table

### Result: Cleaned_GP

```{R}
kable(head(Cleaned_GP))
```
